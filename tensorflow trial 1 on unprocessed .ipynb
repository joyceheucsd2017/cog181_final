{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dicom # for reading dicom files\n",
    "import os # for doing directory operations \n",
    "import pandas as pd # for some simple data analysis (right now, just to load in the labels data and quickly reference it)\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change this to wherever you are storing your data:\n",
    "# IF YOU ARE FOLLOWING ON KAGGLE, YOU CAN ONLY PLAY WITH THE SAMPLE DATA, WHICH IS MUCH SMALLER\n",
    "\n",
    "data_dir = '/media/ai-master/my_passport/joyce/Sample Image/'\n",
    "patients = os.listdir(data_dir)\n",
    "labels_df = pd.read_csv('/media/ai-master/my_passport/joyce/stage1_labels.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "IMG_SIZE_PX = 50\n",
    "SLICE_COUNT = 20\n",
    "\n",
    "def chunks( l,n ):\n",
    "    count=0\n",
    "    for i in range(0, len(l), n):\n",
    "        if(count < HM_SLICES):\n",
    "            yield l[i:i + n]\n",
    "            count=count+1\n",
    "\n",
    "\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)\n",
    "\n",
    "\n",
    "def process_data(patient,labels_df,img_px_size=50, hm_slices=20, visualize=False):\n",
    "    \n",
    "    label = labels_df.get_value(patient, 'cancer')\n",
    "    path = data_dir + patient\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "\n",
    "    new_slices = []\n",
    "    slices = [cv2.resize(np.array(each_slice.pixel_array),(img_px_size,img_px_size)) for each_slice in slices]\n",
    "    \n",
    "    chunk_sizes = int(math.floor(len(slices) / HM_SLICES))\n",
    "    for slice_chunk in chunks(slices, chunk_sizes):\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        new_slices.append(slice_chunk)\n",
    "\n",
    "    if len(new_slices) == hm_slices-1:\n",
    "        new_slices.append(new_slices[-1])\n",
    "\n",
    "    if len(new_slices) == hm_slices-2:\n",
    "        new_slices.append(new_slices[-1])\n",
    "        new_slices.append(new_slices[-1])\n",
    "\n",
    "    if len(new_slices) > hm_slices:\n",
    "        new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices],])))\n",
    "        del new_slices[hm_slices]\n",
    "        new_slices[hm_slices-1] = new_val\n",
    "        \n",
    "    if len(new_slices) == hm_slices+1:\n",
    "        new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices],])))\n",
    "        del new_slices[hm_slices]\n",
    "        new_slices[hm_slices-1] = new_val\n",
    "\n",
    "    if visualize:\n",
    "        fig = plt.figure()\n",
    "        for num,each_slice in enumerate(new_slices):\n",
    "            y = fig.add_subplot(4,5,num+1)\n",
    "            y.imshow(each_slice, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    if label == 1: label=np.array([0,1])\n",
    "    elif label == 0: label=np.array([1,0])\n",
    "        \n",
    "    return np.array(new_slices),label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'HM_SLICES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b012e1bf44d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_px_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE_PX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhm_slices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSLICE_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(img_data.shape,label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmuch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ca126201282e>\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(patient, labels_df, img_px_size, hm_slices, visualize)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_px_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_px_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mchunk_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mHM_SLICES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mslice_chunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mslice_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mslice_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'HM_SLICES' is not defined"
     ]
    }
   ],
   "source": [
    "#                                               stage 1 for real.\n",
    "path = '/media/ai-master/my_passport/joyce/pre_3d/'\n",
    "data_dir = '/media/ai-master/my_passport/joyce/stage1/'\n",
    "patients = os.listdir(data_dir)\n",
    "labels = pd.read_csv('/media/ai-master/my_passport/joyce/stage1_labels.csv', index_col=0)\n",
    "\n",
    "much_data = []\n",
    "for num,patient in enumerate(patients):\n",
    "    if num % 100 == 0:\n",
    "        print(num)\n",
    "    try:\n",
    "        img_data,label = process_data(patient,labels,img_px_size=IMG_SIZE_PX, hm_slices=SLICE_COUNT)\n",
    "        #print(img_data.shape,label)\n",
    "        much_data.append([img_data,label])\n",
    "    except KeyError as e:\n",
    "        print('This is unlabeled data!')\n",
    "\n",
    "np.save('muchdata-{}-{}-{}.npy'.format(IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT), much_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE_PX = 50\n",
    "SLICE_COUNT = 20\n",
    "\n",
    "n_classes = 2\n",
    "batch_size = 10\n",
    "\n",
    "x = tf.placeholder('float')\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "keep_rate = 0.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool3d(x):\n",
    "    #                        size of window         movement of window as you slide about\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x):\n",
    "    #                # 5 x 5 x 5 patches, 1 channel, 32 features to compute.\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,1,32])),\n",
    "               #       5 x 5 x 5 patches, 32 channels, 64 features to compute.\n",
    "               'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),\n",
    "               #                                  64 features\n",
    "               'W_fc':tf.Variable(tf.random_normal([54080,1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "               'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    #                            image X      image Y        image Z\n",
    "    x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool3d(conv1)\n",
    "\n",
    "\n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool3d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, 54080])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "much_data = np.load('muchdata-50-50-20.npy')\n",
    "# If you are working with the basic sample data, use maybe 2 instead of 100 here... you don't have enough data to really do this\n",
    "train_data = much_data[:-100]\n",
    "validation_data = much_data[-100:]\n",
    "\n",
    "\n",
    "\n",
    "prediction = convolutional_neural_network(x)\n",
    "cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=10**-3).minimize(cost)\n",
    "a = tf.cast(tf.argmax(prediction, 1),tf.float32)\n",
    "b = tf.cast(tf.argmax(y,1),tf.float32)\n",
    "auc = tf.contrib.metrics.streaming_auc(a, b)\n",
    "hm_epochs = 50\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-6bb3343f8feb>:3: initialize_local_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.local_variables_initializer` instead.\n",
      "('Epoch', 1, 'completed out of', 50, 'loss:', 201894034.10832691)\n",
      "('Accuracy:', 0.65999997)\n",
      "('Epoch', 2, 'completed out of', 50, 'loss:', 15797974.982074017)\n",
      "('Accuracy:', 0.69)\n",
      "('Epoch', 3, 'completed out of', 50, 'loss:', 5776794.2952968385)\n",
      "('Accuracy:', 0.58999991)\n",
      "('Epoch', 4, 'completed out of', 50, 'loss:', 3306051.7332787202)\n",
      "('Accuracy:', 0.47999999)\n",
      "('Epoch', 5, 'completed out of', 50, 'loss:', 1735958.5535008674)\n",
      "('Accuracy:', 0.66999996)\n",
      "('Epoch', 6, 'completed out of', 50, 'loss:', 983361.15527720226)\n",
      "('Accuracy:', 0.57999998)\n",
      "('Epoch', 7, 'completed out of', 50, 'loss:', 694363.34969370416)\n",
      "('Accuracy:', 0.58999997)\n",
      "('Epoch', 8, 'completed out of', 50, 'loss:', 392055.49649048294)\n",
      "('Accuracy:', 0.52999997)\n",
      "('Epoch', 9, 'completed out of', 50, 'loss:', 206870.49961786365)\n",
      "('Accuracy:', 0.66999996)\n",
      "('Epoch', 10, 'completed out of', 50, 'loss:', 125682.17820550909)\n",
      "('Accuracy:', 0.48999998)\n",
      "('Epoch', 11, 'completed out of', 50, 'loss:', 159136.8932817569)\n",
      "('Accuracy:', 0.55999994)\n",
      "('Epoch', 12, 'completed out of', 50, 'loss:', 89126.516144919718)\n",
      "('Accuracy:', 0.48999998)\n",
      "('Epoch', 13, 'completed out of', 50, 'loss:', 178003.59963334573)\n",
      "('Accuracy:', 0.55999994)\n",
      "('Epoch', 14, 'completed out of', 50, 'loss:', 79745.136165599703)\n",
      "('Accuracy:', 0.56999999)\n",
      "('Epoch', 15, 'completed out of', 50, 'loss:', 45825.441047587898)\n",
      "('Accuracy:', 0.57999992)\n",
      "('Epoch', 16, 'completed out of', 50, 'loss:', 75932.15240704907)\n",
      "('Accuracy:', 0.58999997)\n",
      "('Epoch', 17, 'completed out of', 50, 'loss:', 78764.429188289956)\n",
      "('Accuracy:', 0.62)\n",
      "('Epoch', 18, 'completed out of', 50, 'loss:', 77765.221304217906)\n",
      "('Accuracy:', 0.51999998)\n",
      "('Epoch', 19, 'completed out of', 50, 'loss:', 85358.091466311598)\n",
      "('Accuracy:', 0.48999998)\n",
      "('Epoch', 20, 'completed out of', 50, 'loss:', 113978.84542640448)\n",
      "('Accuracy:', 0.55999994)\n",
      "('Epoch', 21, 'completed out of', 50, 'loss:', 35838.940322261689)\n",
      "('Accuracy:', 0.60000002)\n",
      "('Epoch', 22, 'completed out of', 50, 'loss:', 34092.978974492515)\n",
      "('Accuracy:', 0.49000001)\n",
      "('Epoch', 23, 'completed out of', 50, 'loss:', 93978.364250175699)\n",
      "('Accuracy:', 0.65999997)\n",
      "('Epoch', 24, 'completed out of', 50, 'loss:', 51372.420013899355)\n",
      "('Accuracy:', 0.61000001)\n",
      "('Epoch', 25, 'completed out of', 50, 'loss:', 29446.516142938668)\n",
      "('Accuracy:', 0.62)\n",
      "('Epoch', 26, 'completed out of', 50, 'loss:', 24821.55132705858)\n",
      "('Accuracy:', 0.60999995)\n",
      "('Epoch', 27, 'completed out of', 50, 'loss:', 74397.807008393196)\n",
      "('Accuracy:', 0.62)\n",
      "('Epoch', 28, 'completed out of', 50, 'loss:', 33052.321353258892)\n",
      "('Accuracy:', 0.54999995)\n",
      "('Epoch', 29, 'completed out of', 50, 'loss:', 32049.444899770733)\n",
      "('Accuracy:', 0.64999998)\n",
      "('Epoch', 30, 'completed out of', 50, 'loss:', 20135.842764574649)\n",
      "('Accuracy:', 0.63999999)\n",
      "('Epoch', 31, 'completed out of', 50, 'loss:', 23968.257734177572)\n",
      "('Accuracy:', 0.64999998)\n",
      "('Epoch', 32, 'completed out of', 50, 'loss:', 34445.571063228264)\n",
      "('Accuracy:', 0.49000004)\n",
      "('Epoch', 33, 'completed out of', 50, 'loss:', 49067.54789029016)\n",
      "('Accuracy:', 0.47)\n",
      "('Epoch', 34, 'completed out of', 50, 'loss:', 35672.905450756698)\n",
      "('Accuracy:', 0.59000003)\n",
      "('Epoch', 35, 'completed out of', 50, 'loss:', 100438.01148950265)\n",
      "('Accuracy:', 0.60999995)\n",
      "('Epoch', 36, 'completed out of', 50, 'loss:', 90599.567073478931)\n",
      "('Accuracy:', 0.60999995)\n",
      "('Epoch', 37, 'completed out of', 50, 'loss:', 15887.213108996597)\n",
      "('Accuracy:', 0.65999997)\n",
      "('Epoch', 38, 'completed out of', 50, 'loss:', 14825.519253947341)\n",
      "('Accuracy:', 0.53999996)\n",
      "('Epoch', 39, 'completed out of', 50, 'loss:', 842.2068985043469)\n",
      "('Accuracy:', 0.56999993)\n",
      "('Epoch', 40, 'completed out of', 50, 'loss:', 110445.77392958467)\n",
      "('Accuracy:', 0.54999995)\n",
      "('Epoch', 41, 'completed out of', 50, 'loss:', 19210.710205530246)\n",
      "('Accuracy:', 0.53999996)\n",
      "('Epoch', 42, 'completed out of', 50, 'loss:', 26861.881307209784)\n",
      "('Accuracy:', 0.65999997)\n",
      "('Epoch', 43, 'completed out of', 50, 'loss:', 1862.7455077883067)\n",
      "('Accuracy:', 0.59999996)\n",
      "('Epoch', 44, 'completed out of', 50, 'loss:', 62709.63970103785)\n",
      "('Accuracy:', 0.5)\n",
      "('Epoch', 45, 'completed out of', 50, 'loss:', 19747.091280173525)\n",
      "('Accuracy:', 0.59999996)\n",
      "('Epoch', 46, 'completed out of', 50, 'loss:', 39073.365948152561)\n",
      "('Accuracy:', 0.46999997)\n",
      "('Epoch', 47, 'completed out of', 50, 'loss:', 28012.614226669153)\n",
      "('Accuracy:', 0.54999995)\n",
      "('Epoch', 48, 'completed out of', 50, 'loss:', 4955.4891509068229)\n",
      "('Accuracy:', 0.61000001)\n",
      "('Epoch', 49, 'completed out of', 50, 'loss:', 4655.3067125686957)\n",
      "('Accuracy:', 0.63999999)\n",
      "('Epoch', 50, 'completed out of', 50, 'loss:', 13341.498117698398)\n",
      "('Accuracy:', 0.57999998)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument must be a dense tensor:                                   cancer\nid                                      \n0015ceb851d7251b8f399e39779d1e7d       1\n0030a160d58723ff36d73f41b170ec21       0\n003f41c78e6acfa92430a057ac0b306e       0\n006b96310a37b36cccb2ab48d10b49a3       1\n008464bb8521d09a42985dd8add3d0d2       1\n0092c13f9e00a3717fdc940641f00015       0\n00986bebc45e12038ef0ce3e9962b51a       0\n00cba091fa4ad62cc3200a657aeb957e       0\n00edff4f51a893d80dae2d42a7f45ad1       1\n0121c2845f2b7df060945b072b2515d7       0\n013395589c01aa01f8df81d80fb0e2b8       0\n01de8323fa065a8963533c4a86f2f6c1       0\n01e349d34c06410e1da273add27be25c       0\n01f1140c8e951e2a921b61c9a7e782c2       0\n024efb7a1e67dc820eb61cbdaa090166       0\n0257df465d9e4150adef13303433ff1e       1\n0268f3a7a17412178cfb039e71799a80       0\n026be5d5e652b6a7488669d884ebe297       0\n02801e3bbcc6966cb115a962012c35df       1\n028996723faa7840bb57f57e28275e4c       1\n0334c8242ce7ee1a6c1263096e4cc535       0\n03fb0d0fdb187ee1160f09386b28c3f2       0\n03ff23e445787886f8b0cb192b3c154d       0\n043ed6cb6054cc13804a3dca342fa4d0       0\n0482c444ac838adc5aa00d1064c976c1       0\n04a3187ec2ed4198a25033071897bffc       0\n04a52f49cdbfb8b99789b9e93f1ad319       0\n04a8c47583142181728056310759dea1       1\n04cfc5efa4c8c2a8944c8b9fa6cb04d1       0\n04e5d435fa01b0958e3274be73312cac       0\n...                                  ...\nfa45178d023325b255a3d4fc3e96cb7d       1\nfa744c0374ccc6aaf6711f463a9e5bc2       0\nfa7bf17071e3234ab1f350341303b174       0\nfa9575f64e6881c6b2730f0e225c9573       0\nfa968673987cfd078d91641294c3bf63       0\nfac65dbf7b6972049cfd37b5b122ec0b       0\nfb52dd8152e53a4ca7da5403d6d0db13       0\nfb57fc6377fd37bb5d42756c2736586c       1\nfb7ae70f05b6441ac4ea7187ce7c45f7       0\nfb7dfb6aae597d97c2da24179df0fe56       0\nfb99a80cbb2f441bb90135bab5b029fe       1\nfbaa8548e6c3753836579c7987d0034d       0\nfbae4d04285789dfa32124c86586dd09       1\nfbe0c3d6e4a50ca1c1bd3101515d0ab4       0\nfc545aa2f58509dc6d81ef02130b6906       1\nfc658f9bc12a751a17f16589f9e3619b       0\nfcdc2d423356d53759a8f602d40785a6       0\nfd0c2dfe0b0c58330675c3191cef0d5b       1\nfd2dd970bd3d91e5b26d7e57c03f70af       1\nfd4c2d4738bc25a5c331dbc101f3323a       0\nfd64b23b8cd8c371c8f76fbb503e4e0e       0\nfd7c0fb3c0e764357aa58e5f047be614       0\nfda187bfb1d6a2ecd4abd862c7f7f94c       1\nfdf2a2f5b86aea0da54732056fc7ab48       0\nfdf73dcce35167f3ed952a58f5a6f738       0\nfe26fd2bb25112b3c2ca93eb8e34f8ed       0\nfe45462987bacc32dbc7126119999392       1\nfe5c37e82b412833b8ad0abb57978377       0\nff5d8e90500cf324e7b04a2f07cf0399       0\nffe02fe7d2223743f7fb455dfaff3842       0\n\n[1397 rows x 1 columns] - got shape [1397, 1], but wanted [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6bb3343f8feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     auc = tf.metrics.auc(labels, pred, weights=None, \n\u001b[1;32m     39\u001b[0m                          \u001b[0mnum_thresholds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                          curve='ROC', name=None) \n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"temp/model4.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auc:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ai-master/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/metrics_impl.pyc\u001b[0m in \u001b[0;36mauc\u001b[0;34m(labels, predictions, weights, num_thresholds, metrics_collections, updates_collections, curve, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     values, update_ops = _confusion_matrix_at_thresholds(\n\u001b[0;32m--> 548\u001b[0;31m         labels, predictions, thresholds, weights)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;31m# Add epsilons to avoid dividing by 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ai-master/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/metrics_impl.pyc\u001b[0m in \u001b[0;36m_confusion_matrix_at_thresholds\u001b[0;34m(labels, predictions, thresholds, weights, includes)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invaild key: %s.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   labels, predictions, weights = _remove_squeezable_dimensions(\n",
      "\u001b[0;32m/home/ai-master/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    739\u001b[0m       \u001b[0;31m# allows some conversions that cast() can't do, e.g.  casting numbers to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m       \u001b[0;31m# strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ai-master/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    649\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ai-master/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ai-master/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    174\u001b[0m                                          as_ref=False):\n\u001b[1;32m    175\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ai-master/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 165\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    166\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/home/ai-master/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    374\u001b[0m                          \"\"\" - got shape %s, but wanted %s.\"\"\" % (\n\u001b[1;32m    375\u001b[0m                              \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              _GetDenseDimensions(values)))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;31m# python/numpy default float type is float64. We prefer float32 instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument must be a dense tensor:                                   cancer\nid                                      \n0015ceb851d7251b8f399e39779d1e7d       1\n0030a160d58723ff36d73f41b170ec21       0\n003f41c78e6acfa92430a057ac0b306e       0\n006b96310a37b36cccb2ab48d10b49a3       1\n008464bb8521d09a42985dd8add3d0d2       1\n0092c13f9e00a3717fdc940641f00015       0\n00986bebc45e12038ef0ce3e9962b51a       0\n00cba091fa4ad62cc3200a657aeb957e       0\n00edff4f51a893d80dae2d42a7f45ad1       1\n0121c2845f2b7df060945b072b2515d7       0\n013395589c01aa01f8df81d80fb0e2b8       0\n01de8323fa065a8963533c4a86f2f6c1       0\n01e349d34c06410e1da273add27be25c       0\n01f1140c8e951e2a921b61c9a7e782c2       0\n024efb7a1e67dc820eb61cbdaa090166       0\n0257df465d9e4150adef13303433ff1e       1\n0268f3a7a17412178cfb039e71799a80       0\n026be5d5e652b6a7488669d884ebe297       0\n02801e3bbcc6966cb115a962012c35df       1\n028996723faa7840bb57f57e28275e4c       1\n0334c8242ce7ee1a6c1263096e4cc535       0\n03fb0d0fdb187ee1160f09386b28c3f2       0\n03ff23e445787886f8b0cb192b3c154d       0\n043ed6cb6054cc13804a3dca342fa4d0       0\n0482c444ac838adc5aa00d1064c976c1       0\n04a3187ec2ed4198a25033071897bffc       0\n04a52f49cdbfb8b99789b9e93f1ad319       0\n04a8c47583142181728056310759dea1       1\n04cfc5efa4c8c2a8944c8b9fa6cb04d1       0\n04e5d435fa01b0958e3274be73312cac       0\n...                                  ...\nfa45178d023325b255a3d4fc3e96cb7d       1\nfa744c0374ccc6aaf6711f463a9e5bc2       0\nfa7bf17071e3234ab1f350341303b174       0\nfa9575f64e6881c6b2730f0e225c9573       0\nfa968673987cfd078d91641294c3bf63       0\nfac65dbf7b6972049cfd37b5b122ec0b       0\nfb52dd8152e53a4ca7da5403d6d0db13       0\nfb57fc6377fd37bb5d42756c2736586c       1\nfb7ae70f05b6441ac4ea7187ce7c45f7       0\nfb7dfb6aae597d97c2da24179df0fe56       0\nfb99a80cbb2f441bb90135bab5b029fe       1\nfbaa8548e6c3753836579c7987d0034d       0\nfbae4d04285789dfa32124c86586dd09       1\nfbe0c3d6e4a50ca1c1bd3101515d0ab4       0\nfc545aa2f58509dc6d81ef02130b6906       1\nfc658f9bc12a751a17f16589f9e3619b       0\nfcdc2d423356d53759a8f602d40785a6       0\nfd0c2dfe0b0c58330675c3191cef0d5b       1\nfd2dd970bd3d91e5b26d7e57c03f70af       1\nfd4c2d4738bc25a5c331dbc101f3323a       0\nfd64b23b8cd8c371c8f76fbb503e4e0e       0\nfd7c0fb3c0e764357aa58e5f047be614       0\nfda187bfb1d6a2ecd4abd862c7f7f94c       1\nfdf2a2f5b86aea0da54732056fc7ab48       0\nfdf73dcce35167f3ed952a58f5a6f738       0\nfe26fd2bb25112b3c2ca93eb8e34f8ed       0\nfe45462987bacc32dbc7126119999392       1\nfe5c37e82b412833b8ad0abb57978377       0\nff5d8e90500cf324e7b04a2f07cf0399       0\nffe02fe7d2223743f7fb455dfaff3842       0\n\n[1397 rows x 1 columns] - got shape [1397, 1], but wanted []."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.initialize_local_variables()) # try commenting this line and you'll get the error\n",
    "    successful_runs = 0\n",
    "    total_runs = 0\n",
    "\n",
    "    for epoch in range(hm_epochs):\n",
    "        epoch_loss = 0\n",
    "        for data in train_data:\n",
    "            total_runs += 1\n",
    "            try:\n",
    "                X = data[0]\n",
    "                Y = data[1]\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
    "                epoch_loss += c\n",
    "                successful_runs += 1\n",
    "            except Exception as e:\n",
    "                # I am passing for the sake of notebook space, but we are getting 1 shaping issue from one \n",
    "                # input tensor. Not sure why, will have to look into it. Guessing it's\n",
    "                # one of the depths that doesn't come to 20.\n",
    "                pass\n",
    "                #print(str(e))\n",
    "\n",
    "        print('Epoch', epoch+1, 'completed out of',hm_epochs,'loss:',epoch_loss/len(train_data))\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "        print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n",
    "\n",
    "#         pred=tf.argmax(prediction,1)\n",
    "#         pred.eval(feed_dict={x: [i[0] for i in validation_data]})\n",
    "#         \n",
    "        pred = tf.argmax(prediction, 1).eval({x:[i[0] for i in validation_data]})\n",
    "\n",
    "#         tf.metrics.auc(label, pred)\n",
    "    label = [i[1] for i in validation_data]\n",
    "    auc = tf.metrics.auc(labels, pred, weights=None, \n",
    "                         num_thresholds=200, metrics_collections=None, updates_collections=None, \n",
    "                         curve='ROC', name=None) \n",
    "    save_path = saver.save(sess, \"temp/model4.ckpt\")\n",
    "    print('auc:',auc)\n",
    "    print('Done. Finishing accuracy:')\n",
    "    print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n",
    "    \n",
    "    print('fitment percent:',successful_runs/total_runs)\n",
    "\n",
    "# Run this locally:\n",
    "#train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy:', 0.71999997)\n",
      "Tensor(\"ArgMax_338:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess, \"temp/model3.ckpt\")\n",
    "\n",
    "    print('Validation Accuracy:',\n",
    "          accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n",
    "\n",
    "#     sess.close()\n",
    "#     print('training Accuracy:',\n",
    "#           accuracy.eval({x:[i[0] for i in train_data], y:[i[1] for i in train_data]}))\n",
    "    print pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  4.81511328e+08,  -3.50462336e+08]], dtype=float32), array([[  4.33265760e+08,   2.67488112e+08]], dtype=float32), array([[  4.02388576e+08,  -9.18245056e+08]], dtype=float32), array([[  8.62159808e+08,  -1.67334413e+09]], dtype=float32), array([[ -4.82582592e+08,  -5.95553408e+08]], dtype=float32), array([[ -4.81497440e+08,   2.04550848e+08]], dtype=float32), array([[ -2.70466944e+08,  -5.56810368e+08]], dtype=float32), array([[  7.39532608e+08,  -2.61643664e+08]], dtype=float32), array([[  3.29593856e+08,  -2.73537152e+08]], dtype=float32), array([[  1.32420557e+09,   3.34509632e+08]], dtype=float32), array([[  2.46718352e+08,  -1.09019443e+09]], dtype=float32), array([[  9.86950912e+08,  -4.29186272e+08]], dtype=float32), array([[  7.13097856e+08,   3.11522944e+08]], dtype=float32), array([[  9.30033664e+08,  -1.16569536e+08]], dtype=float32), array([[  8.25865600e+07,  -4.01317248e+08]], dtype=float32), array([[  7.65082304e+08,  -4.20561760e+08]], dtype=float32), array([[  5.17610304e+08,  -8.04373680e+07]], dtype=float32), array([[ -1.68595392e+08,  -1.00300102e+09]], dtype=float32), array([[  4.15902880e+07,  -1.26050598e+09]], dtype=float32), array([[ -7.67694080e+07,  -8.44474880e+08]], dtype=float32), array([[  2.20155520e+07,  -1.16682867e+09]], dtype=float32), array([[ -5.45049792e+08,  -1.63885414e+09]], dtype=float32), array([[  9.14439872e+08,  -6.43666304e+08]], dtype=float32), array([[  3.38160704e+08,   1.22247088e+08]], dtype=float32), array([[  9.19267712e+08,  -5.94904960e+08]], dtype=float32), array([[  2.28641840e+07,  -1.70897984e+09]], dtype=float32), array([[  5.93381760e+08,  -3.48322464e+08]], dtype=float32), array([[  1.29052250e+09,  -5.98918656e+08]], dtype=float32), array([[  4.37111808e+08,  -4.35074816e+08]], dtype=float32), array([[  1.74876749e+09,  -1.53932480e+09]], dtype=float32), array([[ -2.49124000e+08,  -8.14703296e+08]], dtype=float32), array([[ -2.92296880e+07,  -2.06523680e+08]], dtype=float32), array([[  6.68086528e+08,  -2.84330144e+08]], dtype=float32), array([[  2.74820928e+08,  -4.94919520e+08]], dtype=float32), array([[  4.06423776e+08,   2.89823000e+07]], dtype=float32), array([[  5.02795072e+08,  -2.53451680e+07]], dtype=float32), array([[  2.03429171e+09,  -1.79883162e+09]], dtype=float32), array([[  2.14738982e+09,  -3.02160992e+08]], dtype=float32), array([[  8.33437440e+08,  -8.80743616e+08]], dtype=float32), array([[  9.38704320e+08,  -1.52730784e+08]], dtype=float32), array([[  3.93357152e+08,  -5.97974912e+08]], dtype=float32), array([[  9.42123008e+08,  -6.65112768e+08]], dtype=float32), array([[  5.99394560e+08,  -7.69682496e+08]], dtype=float32), array([[  2.32739440e+08,  -3.52416064e+08]], dtype=float32), array([[  5.18531552e+08,  -6.78409344e+08]], dtype=float32), array([[ -9.82504320e+07,  -7.92643328e+08]], dtype=float32), array([[ -7.56907712e+08,  -1.67344960e+09]], dtype=float32), array([[  7.20476288e+08,  -7.10955136e+08]], dtype=float32), array([[  2.93323392e+08,  -1.34194522e+09]], dtype=float32), array([[  8.02188544e+08,   6.84028160e+08]], dtype=float32), array([[  3.45967552e+08,  -9.71655232e+08]], dtype=float32), array([[  7.60398080e+08,  -4.69639264e+08]], dtype=float32), array([[  8.19621920e+07,  -1.03632934e+09]], dtype=float32), array([[  3.86920832e+08,  -7.36757760e+07]], dtype=float32), array([[  9.93280512e+08,  -8.07781056e+08]], dtype=float32), array([[  8.40880960e+08,  -5.24127680e+08]], dtype=float32), array([[  3.84470688e+08,  -3.27168320e+08]], dtype=float32), array([[-57350656.,  56766084.]], dtype=float32), array([[  2.86583680e+08,  -9.45627456e+08]], dtype=float32), array([[  7.74309824e+08,  -4.25254592e+08]], dtype=float32), array([[  1.83874544e+08,  -1.45793056e+08]], dtype=float32), array([[  4.71381440e+08,   5.22483488e+08]], dtype=float32), array([[  9.11409920e+08,   6.84127200e+07]], dtype=float32), array([[ -4.72290480e+07,  -1.45590960e+08]], dtype=float32), array([[  5.66828864e+08,  -1.86435808e+08]], dtype=float32), array([[  9.12134464e+08,  -2.50432192e+08]], dtype=float32), array([[  2.10957680e+08,  -1.17941608e+08]], dtype=float32), array([[  3.66321984e+08,  -2.27265120e+08]], dtype=float32), array([[  3.58025920e+08,  -4.36436864e+08]], dtype=float32), array([[  9.80787712e+08,  -1.16825766e+09]], dtype=float32), array([[  2.04444736e+08,  -1.28246682e+09]], dtype=float32), array([[  1.35301133e+09,  -2.75345376e+08]], dtype=float32), array([[  7.12784640e+08,  -8.66488128e+08]], dtype=float32), array([[  5.10751392e+08,  -8.04698880e+08]], dtype=float32), array([[  3.98263872e+08,  -7.06274176e+08]], dtype=float32), array([[  2.29885728e+08,  -3.12319296e+08]], dtype=float32), array([[  6.10188864e+08,  -5.69333952e+08]], dtype=float32), array([[ -2.21506416e+08,   7.81668736e+08]], dtype=float32), array([[  9.57823920e+07,  -6.06046400e+08]], dtype=float32), array([[  2.86464064e+08,  -1.10768397e+09]], dtype=float32), array([[  2.92977696e+08,   3.07113280e+08]], dtype=float32), array([[  4.06935360e+08,  -1.19214336e+08]], dtype=float32), array([[  5.65210240e+08,  -6.98074752e+08]], dtype=float32), array([[  4.97868928e+08,  -1.88202880e+08]], dtype=float32), array([[ -1.51546880e+08,  -1.14300301e+09]], dtype=float32), array([[  9.87329920e+08,   2.44712768e+08]], dtype=float32), array([[ -1.04469856e+08,  -1.26358490e+09]], dtype=float32), array([[  4.58140320e+08,  -5.15355872e+08]], dtype=float32), array([[  8.84940032e+08,  -1.94903488e+09]], dtype=float32), array([[ -1.30209968e+08,  -7.90697536e+08]], dtype=float32), array([[  4.61650176e+08,   3.28783296e+08]], dtype=float32), array([[ -5.44977792e+08,  -6.89491072e+08]], dtype=float32), array([[  6.84651520e+08,  -5.23465504e+08]], dtype=float32), array([[  7.69491280e+07,  -2.06465760e+08]], dtype=float32), array([[  5.85357888e+08,  -6.65037312e+08]], dtype=float32), array([[  1.38626189e+09,  -9.56114688e+08]], dtype=float32), array([[  2.55046384e+08,  -1.11764774e+09]], dtype=float32), array([[  1.05174758e+09,   3.97828512e+08]], dtype=float32), array([[  1.57113632e+08,  -1.39824960e+08]], dtype=float32), array([[  6.73022240e+07,   8.09376832e+08]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "745.5101/1297\n",
    "1-0.72"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
